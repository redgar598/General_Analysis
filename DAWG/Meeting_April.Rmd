---
title: "Meeting April"
author: "Redgar"
date: "April 3, 2017"
output: 
  html_document: 
    keep_md: yes
---

```{r message=FALSE}
setwd("~/Documents/Side/DAWG/")
library(rafalib)
library(UsingR)
library(contrast)
```
# Excercise 1
```{r}
g = 9.8
h0 = 56.67
v0 = 0
n = 25
tt = seq(0,3.4,len=n)
y = h0 + v0 *tt - 0.5* g*tt^2 + rnorm(n,sd=1)

X = cbind(1,tt,tt^2)
A = solve(crossprod(X))%*%t(X)

# 1 C
-2 * (A %*% y) [3]

# 2  issue:got same as sam not as alex
se<-function(x) sd(x)/sqrt(length(x))

est_g<-function(x) {
  y = h0 + v0 *tt - 0.5* g*tt^2 + rnorm(n,sd=1)
  X = cbind(1,tt,tt^2)
  A = solve(crossprod(X))%*%t(X)
  -2 * (A %*% y) [3]
}

g_estimates<-replicate(100000,est_g(1), simplify = "array")
se(g_estimates)

# 3

x = father.son$fheight
y = father.son$sheight
n = length(y)

N = 50
index = sample(n,N)
sampledat = father.son[index,]
x = sampledat$fheight
y = sampledat$sheight
betahat = lm(y~x)$coef
slope = lm(y~x)$coef[2]
slope

slope_height<-function(x){
  N = 50
  index = sample(n,N)
  sampledat = father.son[index,]
  x = sampledat$fheight
  y = sampledat$sheight
  betahat = lm(y~x)$coef
  slope = lm(y~x)$coef[2]
  slope
}


slope_estimates<-replicate(10000,slope_height(1), simplify = "array")
se(slope_estimates)

# 4 C

x = father.son$fheight
y = father.son$sheight

mean((y - mean(y))*(x-mean(x)))
```

#### The design matrix
```{r}
group <- factor( c(1,1,2,2) )
model.matrix(~ group)

diet <- factor(c(1,1,1,1,2,2,2,2))
sex <- factor(c("f","f","m","m","f","f","m","m"))
model.matrix(~ diet + sex)
```






#### High fat vs low fat design matrix
```{r}
dat <- read.csv("femaleMiceWeights.csv") ##previously downloaded
stripchart(dat$Bodyweight ~ dat$Diet, vertical=TRUE, method="jitter",main="Bodyweight over Diet")
levels(dat$Diet)

X <- model.matrix(~ Diet, data=dat)
head(X)

Y <- dat$Bodyweight
X <- model.matrix(~ Diet, data=dat)
solve(t(X) %*% X) %*% t(X) %*% Y
#These coefficients are the average of the control group and the difference of the averages:
    ## see manually 
    s <- split(dat$Bodyweight, dat$Diet)
    mean(s[["chow"]])
    mean(s[["hf"]]) - mean(s[["chow"]])

# now with lm (but this lm is simply and just a fancy t-test)
fit <- lm(Bodyweight ~ Diet, data=dat)
summary(fit)
(coefs <- coef(fit))

summary(fit)$coefficients

# now as t test (you get the same t statistic either way)
ttest <- t.test(s[["hf"]], s[["chow"]], var.equal=TRUE)
summary(fit)$coefficients[2,3]

ttest$statistic
```

# Excercise
```{r}
# 1
Nx=5
Ny=7
X <- cbind(rep(1,Nx + Ny),rep(c(0,1),c(Nx, Ny)))

(t(X) %*% X)[1,1]

#2
(t(X) %*% X) #7
```


####  Variance-covariance matrix
```{r}
x <- father.son$fheight
y <- father.son$sheight
n <- length(y)

# Manual SE
n <- nrow(father.son)
N <- 50
index <- sample(n,N)
sampledat <- father.son[index,]
x <- sampledat$fheight
y <- sampledat$sheight
X <- model.matrix(~x)
N <- nrow(X)
p <- ncol(X)
XtXinv <- solve(crossprod(X))
resid <- y - X %*% XtXinv %*% crossprod(X,y)
s <- sqrt( sum(resid^2)/(N-p))
ses <- sqrt(diag(XtXinv))*s

# lm SE
summary(lm(y~x))$coef[,2]
```

# Excercises
```{r}
library(UsingR)
N <- 50
set.seed(1)
index <- sample(n,N)
sampledat <- father.son[index,]
x <- sampledat$fheight
y <- sampledat$sheight
betahat <- lm(y~x)$coef

#1
fit <- lm(y ~ x)
fit$fitted.values

# manual
X <- model.matrix(~x)
XtXinv <- solve(crossprod(X))
resid <- y - X %*% XtXinv %*% crossprod(X,y)
sum(resid^2)

# using lm
sum(fit$residuals^2)



#2
sum(resid^2)/48



#3
N <- 50
X <- cbind(rep(1,N), x)

# or
X <- model.matrix(~x)
solve(t(X) %*% X)[1,1]


#4
sqrt(diag(solve(t(X) %*% X)) * (sum(resid^2)/48))
#standard are slope
sqrt(diag(solve(t(X) %*% X)) * (sum(resid^2)/48))[2]

## also present in lm
summary(fit)
```









#### Interactions and contrasts spider legs!!! 
###### pg 196
```{r}
url <- "https://raw.githubusercontent.com/genomicsclass/dagdata/master/inst/extdata/spider_wolff_gorb_2013.csv"
filename <- "spider_wolff_gorb_2013.csv"
library(downloader)
if (!file.exists(filename)) download(url, filename)
spider <- read.csv(filename, skip=1)

table(spider$leg,spider$type)

# extra fun colors
library("ggsci")

ggplot(spider, aes(type, friction, fill=type))+geom_boxplot()+theme_bw()+facet_wrap(~leg, nrow=1)+scale_fill_simpsons()
```

#### Linear model with one variable
```{r}
spider.sub <- spider[spider$leg == "L1",]
fit <- lm(friction ~ type, data=spider.sub)
summary(fit)

## Coefficients are just the means of each group
(coefs <- coef(fit))
means<-tapply(spider.sub$friction, spider.sub$type, mean)
means

means[2]-means[1]

##  make the model matrix that is inside the lm
X <- model.matrix(~ type, data=spider.sub)
colnames(X)

ggplot(spider.sub, aes(type, friction, fill=type))+geom_boxplot()+theme_bw()+scale_fill_simpsons()

```

Make a plot of a design matrix....
```{r}
imagemat(X, main="Model matrix for linear model with one variable")
```

#### Linear model with two variables
```{r}
X <- model.matrix(~ type + leg, data=spider)
colnames(X)
## THIS IS NOT HELPFUL TO ME
imagemat(X, main="Model matrix for linear model with two factors")

fitTL <- lm(friction ~ type + leg, data=spider)
summary(fitTL)
(coefs <- coef(fitTL))

## least squares estimate of model
Y <- spider$friction
X <- model.matrix(~ type + leg, data=spider)
beta.hat <- solve(t(X) %*% X) %*% t(X) %*% Y
t(beta.hat)

## then from lm it is identical
coefs

## however since the model assumes the effects are additive the L2-3 coefficients are not the same as the difference from the intercept
# the type coefficient is a weighted average of the group mean differences (weighted by the sample size of each group)
spider$group<-paste(spider$leg,spider$type, sep="")
s <- split(spider$friction, spider$group)
means<- sapply(s, mean)
ns <-sapply(s, length)[c(1,3,5,7)]
(w <- ns/sum(ns))#weights
sum(w * (means[c(2,4,6,8)] - means[c(1,3,5,7)]))
```

#### Contrasting coefficients (that were not the intecept, L1 here) contrasts!
```{r}
# can be done using the contrasts package
L3vsL2 <- contrast(fitTL,list(leg="L3",type="pull"),list(leg="L2",type="pull"))
L3vsL2
# contrast matrix to pull out the L2 L3 comparison 
L3vsL2$X
```


#### Linear Model with Interactions
```{r}
X <- model.matrix(~ type + leg + type:leg, data=spider)
colnames(X)
head(X)

## now using lm
fitX <- lm(friction ~ type + leg + type:leg, data=spider)
summary(fitX)
coefs <- coef(fitX)

## contrasts from an interaction model
L2push.vs.pull <- contrast(fitX,list(leg="L2", type = "push"),list(leg="L2", type = "pull"))
L2push.vs.pull
coefs[2] + coefs[6]
```

#### Analysis of variance (here we are taught it only as an F test)
```{r}
## which model is a better fit?
anova(fitX)
# The sum of squares  term can be interpreted as the value of each term to reducing the models sum of squares
# here we manually calculate the term given in the ANOVA

## sum of squares with just the intercept
mu0 <- mean(spider$friction)
(initial.ss <- sum((spider$friction - mu0)^2))

## sum of square with teh type of friction term
s <- split(spider$friction, spider$type)
after.type.ss <- sum( sapply(s, function(x) {
  residual <- x - mean(x)
  sum(residual^2)
  }) )
after.type.ss

(type.ss <- initial.ss - after.type.ss)

## as terms are added to the sum of squares calculation sequentially the order of the terms is important

```



# Exercises pg 224
Question 1
```{r}
species <- factor(c("A","A","B","B"))
condition <- factor(c("control","treated","control","treated"))
model.matrix(~ species + condition)

fit <- lm(sample(1:100,4) ~ species + condition)
contrast(fit,list(species="B", condition = "control"),list(species="A", condition = "treated"))$X
# D) 0 1 -1
```

Question 2
```{r}
# t-value = t-statistic = estimate_mean/std.error
fit <- lm(friction ~ type + leg, data=spider)
summary(fit)$coef[,"t value"]

contrast(fit,list(leg="L4", type = "pull"),list(leg="L2", type = "pull"))
#2.45 
```

Question 3
```{r}
cT<-contrast(fit,list(leg="L4", type = "pull"),list(leg="L2", type = "pull"))$X
#We would have obtained the same result for a contrast of L3 and L2 had we picked type="push
X <- model.matrix(~ type + leg, data=spider)
Sigma.hat <- sum(fit$residuals^2)/(nrow(X) - ncol(X)) * solve(t(X) %*% X)
signif(Sigma.hat, 2)
sqrt(cT %*% Sigma.hat %*% t(cT))

## or
contrast(fit,list(leg="L4", type = "pull"),list(leg="L2", type = "pull"))$SE
#0.04462392
```

Question 4
```{r}
spider$log2friction <- log2(spider$friction)
ggplot(spider, aes(type, log2friction, fill=type))+geom_boxplot()+theme_bw()+facet_wrap(~leg, nrow=1)+scale_fill_simpsons()

fitX <- lm(log2friction ~ type + leg + type:leg, data=spider)
summary(fitX)
coefs <- coef(fitX)

summary(fitX)$coef["typepush:legL4","t value"]

#-3.688549
```

Question 5
```{r}
anova(fitX)
#10.701 

```

Question 6
```{r}
contrast(fitX,list(leg="L1", type = "pull"),list(leg="L2", type = "pull"))
#-0.3468125
```

Question 7
```{r}
contrast(fitX,list(leg="L1", type = "push"),list(leg="L2", type = "push"))
#-0.4464843
```



## Colinearity
Don't do it.

#### Rank
Rank of a matrix is the number if independent columns in the matrix. It is a test for confounding. If all columns are not independent than rank < ncol. In R qr calculates rank of a design matrix.
```{r}
# example where treatment and rank are confounded
Sex <- c(0,0,0,0,1,1,1,1)
A <-c(1,1,0,0,0,0,0,0)
B <-c(0,0,1,1,0,0,0,0)
C <-c(0,0,0,0,1,1,0,0)
D <-c(0,0,0,0,0,0,1,1)
X <- model.matrix(~Sex+A+B+C+D-1)
cat("ncol=",ncol(X),"rank=", qr(X)$rank,"\n")
```

#### Removing confounding
Design ya shit better.




# Exercises pg 231
Question 1
```{r}
# I think B but I will test
A <-c(1,1,1,1)
B <-c(0,0,1,1)
C <-c(0,1,0,1)
D <-c(1,1,0,0)
X <- model.matrix(~A+B+C+D-1)
cat("ncol=",ncol(X),"rank=", qr(X)$rank,"\n")

# you are an idiot

# maybe D?
A <-c(0,0,1,1,0,0)
B <-c(0,0,0,0,1,1)
C <-c(0,0,1,1,1,1)
D <-c(0,1,0,1,0,1)
E <-c(1,1,1,1,1,1)

X <- model.matrix(~E+A+B+C+D-1)
cat("ncol=",ncol(X),"rank=", qr(X)$rank,"\n")

# ya fool

#F?
A <-c(0,0,0,1,1,1)
B <-c(0,0,1,0,0,1)
C <-c(1,1,1,0,0,0)
D <-c(1,1,1,1,1,1)
X <- model.matrix(~D+A+B+C-1)
cat("ncol=",ncol(X),"rank=", qr(X)$rank,"\n")

#A
A <-c(0,0,0)
B <-c(0,0,0)
C <-c(1,1,0)
D <-c(1,0,1)
X <- model.matrix(~A+B+C+D-1)
cat("ncol=",ncol(X),"rank=", qr(X)$rank,"\n")

#E!?!?!
A <-c(1,1,1,1)
B <-c(0,0,1,1)
C <-c(0,1,0,1)
D <-c(0,0,0,1)
X <- model.matrix(~A+B+C+D-1)
cat("ncol=",ncol(X),"rank=", qr(X)$rank,"\n")

# it was E....

```

Question 2
```{r}
#set up confounded example
sex <- factor(rep(c("female","male"),each=4))
trt <- factor(c("A","A","B","B","C","C","D","D"))

X <- model.matrix( ~ sex + trt)
qr(X)$rank
ncol(X)

# outcome
Y <- 1:8

makeYstar <- function(a,b) Y - X[,2] * a - X[,5] * b
fitTheRest <- function(a,b) {
Ystar <- makeYstar(a,b)
Xrest <- X[,-c(2,5)]
betarest <- solve(t(Xrest) %*% Xrest) %*% t(Xrest) %*% Ystar
residuals <- Ystar - Xrest %*% betarest
sum(residuals^2)
}

# fit an exmaple for fixed coefficients
#a=coef male
#b=coef of D treatment

makeYstar(1,2)
fitTheRest(1,2)
```

Question 3
```{r}
outer(-2:8,-2:8,Vectorize(fitTheRest))
min(outer(-2:8,-2:8,Vectorize(fitTheRest)))
```

